{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Deploying a Decision Optimization model with Watson Machine Learning\n\nThis notebook shows you how to deploy a Decision Optimization model, create and monitor jobs, and get solutions using the Watson Machine Learning Python Client.\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Table of Contents\n1. [Install the Watson Machine Learning client API](#setup)\n2. [Create a client instance](#create)\n3. [Prepare your model archive](#prepare)\n4. [Upload your model on Watson Machine Learning](#upload)\n5. [Create a deployment](#deploy)\n6. [Create and monitor a job with inline data for your deployed model](#job)\n7. [Display the solution](#display)\n8. [Solve another problem using the same deployment](#problem)\n9. [Summary](#summary)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='setup'></a>\n### Set up the Watson Machine Learning client\n\nBefore you use the sample code in this notebook, you need to:\n\n- create a <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning (WML) Service</a> instance. A free plan is offered and information about how to create the instance can be found at <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\"> https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/wml-setup.html.</a>\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Install and then import the Watson Machine Learning client library. This notebook uses the preview Python client based on v4 of Watson Machine Learning APIs. \n\n**Important** Do not load both Python client libraries into a notebook."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Uninstall the Watson Machine Learning client Python client based on v3 APIs\n\n!pip uninstall watson-machine-learning-client -y"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# Install WML client API\n\n!pip install ibm-watson-machine-learning"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "from ibm_watson_machine_learning import APIClient"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='create'></a>\n### Create a client instance\n\nUse your Watson Machine Learning credentials. You can find infos on how to get your API key and instance's URL <a href=\"https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/DeployModelRest.html?audience=wdp\">here</a> in the second step of the \"Before you begin\" section."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Instantiate a client using credentials\n# You may want to change the URL depending on the instance you are using.\nwml_credentials = {\n      \"apikey\": \"<apikey>\",\n      \"url\": \"https://us-south.ml.cloud.ibm.com\"\n}\n\nclient = APIClient(wml_credentials)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "client.version"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='prepare'></a>\n### Prepare your model archive\n\nPut the model.py file in a subdirectory and create a tar.gz file. The model consists of two parts:\n* some functions to create an `inputs` dictionary from files and create files from an `outputs` dictionary,\n* the real optimization model which uses the inputs and outputs dictionaries.\n\nUse the `write_file` command to write these models to a `main.py` file. \n\nUse the `tar` command to create a tar archive."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "%mkdir model"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "%%writefile model/main.py\n\nfrom docplex.util.environment import get_environment\nfrom os.path import splitext\nimport pandas\nfrom six import iteritems\n\ndef get_all_inputs():\n    '''Utility method to read a list of files and return a tuple with all\n    read data frames.\n    Returns:\n        a map { datasetname: data frame }\n    '''\n    result = {}\n    env = get_environment()\n    for iname in [f for f in os.listdir('.') if splitext(f)[1] == '.csv']:\n        with env.get_input_stream(iname) as in_stream:\n            df = pandas.read_csv(in_stream)\n            datasetname, _ = splitext(iname)\n            result[datasetname] = df\n    return result\n\ndef write_all_outputs(outputs):\n    '''Write all dataframes in ``outputs`` as .csv.\n\n    Args:\n        outputs: The map of outputs 'outputname' -> 'output df'\n    '''\n    for (name, df) in iteritems(outputs):\n        csv_file = '%s.csv' % name\n        print(csv_file)\n        with get_environment().get_output_stream(csv_file) as fp:\n            if sys.version_info[0] < 3:\n                fp.write(df.to_csv(index=False, encoding='utf8'))\n            else:\n                fp.write(df.to_csv(index=False).encode(encoding='utf8'))\n    if len(outputs) == 0:\n        print(\"Warning: no outputs written\")\n        "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "%%writefile -a model/main.py\n\n# Load CSV files into inputs dictionnary\ninputs = get_all_inputs()\n\nfood = inputs['diet_food']\nnutrients = inputs['diet_nutrients']\nfood_nutrients = inputs['diet_food_nutrients']\nfood_nutrients.set_index('Food', inplace=True)\n        \nfrom docplex.mp.model import Model\n\n# Model\nmdl = Model(name='diet')\n\n# Create decision variables, limited to be >= Food.qmin and <= Food.qmax\nqty = food[['name', 'qmin', 'qmax']].copy()\nqty['var'] = qty.apply(lambda x: mdl.continuous_var(lb=x['qmin'],\n                                                ub=x['qmax'],\n                                                name=x['name']),\n                   axis=1)\n# make the name the index\nqty.set_index('name', inplace=True)\n\n# Limit range of nutrients, and mark them as KPIs\nfor n in nutrients.itertuples():\n    amount = mdl.sum(qty.loc[f.name]['var'] * food_nutrients.loc[f.name][n.name]\n                     for f in food.itertuples())\n    mdl.add_range(n.qmin, amount, n.qmax)\n    mdl.add_kpi(amount, publish_name='Total %s' % n.name)\n\n# Minimize cost\nobj = mdl.sum(qty.loc[f.name]['var'] * f.unit_cost for f in food.itertuples())\nmdl.add_kpi(obj, publish_name=\"Minimal cost\");\nmdl.minimize(obj)\n\nmdl.print_information()\n\n# solve\nok = mdl.solve()\n\nmdl.print_solution()\n\nimport pandas\nimport numpy\n\nsolution_df = pandas.DataFrame(columns=['Food', 'value'])\n\nfor index, dvar in enumerate(mdl.solution.iter_variables()):\n    solution_df.loc[index,'Food'] = dvar.to_string()\n    solution_df.loc[index,'value'] = dvar.solution_value\n    \noutputs = {}\noutputs['solution'] = solution_df\n        \n# Generate output files\nwrite_all_outputs(outputs)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import tarfile\ndef reset(tarinfo):\n    tarinfo.uid = tarinfo.gid = 0\n    tarinfo.uname = tarinfo.gname = \"root\"\n    return tarinfo\ntar = tarfile.open(\"model.tar.gz\", \"w:gz\")\ntar.add(\"model/main.py\", arcname=\"main.py\", filter=reset)\ntar.close()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='upload'></a>\n### Upload your model on Watson Machine Learning\n\nStore model in Watson Machine Learning with:\n* the tar archive previously created,\n* metadata including the model type and runtime\n\nGet the `model_uid`."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# All available meta data properties \n\nclient.repository.ModelMetaNames.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Information about the CRNs can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/DeployModelRest.html?audience=wdp\">here</a> in the third and fourth step of the \"Before you begin\" section"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "space_name = '-sample'\ncos_resource_crn = '<COS_crn>'\ninstance_crn = '<instance_crn>'\n\nmetadata = {\n    client.spaces.ConfigurationMetaNames.NAME: 'space' + space_name,\n    client.spaces.ConfigurationMetaNames.DESCRIPTION: space_name + ' description',\n    client.spaces.ConfigurationMetaNames.STORAGE: {\n        \"type\": \"bmcos_object_storage\",\n        \"resource_crn\": cos_resource_crn\n    },\n    client.spaces.ConfigurationMetaNames.COMPUTE: {\n        \"name\": \"existing_instance_id\",\n        \"crn\": instance_crn\n    }\n}\nspace = client.spaces.store(meta_props=metadata)  \nspace_id = client.spaces.get_id(space)\nprint(space_id)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "mnist_metadata = {\n    client.repository.ModelMetaNames.NAME: \"Diet\",\n    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Diet\",\n    client.repository.ModelMetaNames.TYPE: \"do-docplex_12.10\",\n    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_uid_by_name(\"do_12.10\")\n}\n\nclient.set.default_space(space_id)\n\nmodel_details = client.repository.store_model(model='/home/dsxuser/work/model.tar.gz', meta_props=mnist_metadata)\n\nmodel_uid = client.repository.get_model_uid(model_details)\n\nprint( model_uid )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='deploy'></a>\n### Create a deployment \n\nCreate a batch deployment for the model, providing information such as:\n* the maximum number of compute nodes\n* the T-shirt size of the compute nodes\n\nGet the `deployment_uid`."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "meta_props = {\n    client.deployments.ConfigurationMetaNames.NAME: \"Diet Deployment\",\n    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Diet Deployment\",\n    client.deployments.ConfigurationMetaNames.BATCH: {},\n    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {'name': 'S', 'nodes': 1}\n}\n\ndeployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n\ndeployment_uid = client.deployments.get_uid(deployment_details)\n\nprint( deployment_uid )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "# List all existing deployments\n\nclient.deployments.list()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='job'></a>\n### Create and monitor a job with inline data for your deployed model\n\nCreate a payload containing inline input data.\n\nCreate a new job with this payload and the deployment.\n\nGet the `job_uid`."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Import pandas library \nimport pandas as pd \n  \n# initialize list of lists \ndiet_food = pd.DataFrame([ [\"Roasted Chicken\", 0.84, 0, 10],\n                [\"Spaghetti W/ Sauce\", 0.78, 0, 10],\n                [\"Tomato,Red,Ripe,Raw\", 0.27, 0, 10],\n                [\"Apple,Raw,W/Skin\", 0.24, 0, 10],\n                [\"Grapes\", 0.32, 0, 10],\n                [\"Chocolate Chip Cookies\", 0.03, 0, 10],\n                [\"Lowfat Milk\", 0.23, 0, 10],\n                [\"Raisin Brn\", 0.34, 0, 10],\n                [\"Hotdog\", 0.31, 0, 10]] , columns = [\"name\",\"unit_cost\",\"qmin\",\"qmax\"])\n\ndiet_food_nutrients = pd.DataFrame([\n                [\"Spaghetti W/ Sauce\", 358.2, 80.2, 2.3, 3055.2, 11.6, 58.3, 8.2],\n                [\"Roasted Chicken\", 277.4, 21.9, 1.8, 77.4, 0, 0, 42.2],\n                [\"Tomato,Red,Ripe,Raw\", 25.8, 6.2, 0.6, 766.3, 1.4, 5.7, 1],\n                [\"Apple,Raw,W/Skin\", 81.4, 9.7, 0.2, 73.1, 3.7, 21, 0.3],\n                [\"Grapes\", 15.1, 3.4, 0.1, 24, 0.2, 4.1, 0.2],\n                [\"Chocolate Chip Cookies\", 78.1, 6.2, 0.4, 101.8, 0, 9.3, 0.9],\n                [\"Lowfat Milk\", 121.2, 296.7, 0.1, 500.2, 0, 11.7, 8.1],\n                [\"Raisin Brn\", 115.1, 12.9, 16.8, 1250.2, 4, 27.9, 4],\n                [\"Hotdog\", 242.1, 23.5, 2.3, 0, 0, 18, 10.4 ]\n            ] , columns = [\"Food\",\"Calories\",\"Calcium\",\"Iron\",\"Vit_A\",\"Dietary_Fiber\",\"Carbohydrates\",\"Protein\"])\n\ndiet_nutrients = pd.DataFrame([\n                [\"Calories\", 2000, 2500],\n                [\"Calcium\", 800, 1600],\n                [\"Iron\", 10, 30],\n                [\"Vit_A\", 5000, 50000],\n                [\"Dietary_Fiber\", 25, 100],\n                [\"Carbohydrates\", 0, 300],\n                [\"Protein\", 50, 100]\n            ], columns = [\"name\",\"qmin\",\"qmax\"])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "solve_payload = {\n    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n        {\n            \"id\":\"diet_food.csv\",\n            \"values\" : diet_food\n        },\n        {\n            \"id\":\"diet_food_nutrients.csv\",\n            \"values\" : diet_food_nutrients\n        },\n        {\n            \"id\":\"diet_nutrients.csv\",\n            \"values\" : diet_nutrients\n        }\n    ],\n    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n    {\n        \"id\":\".*\\.csv\"\n    }\n    ]\n}\n\njob_details = client.deployments.create_job(deployment_uid, solve_payload)\njob_uid = client.deployments.get_job_uid(job_details)\n\nprint( job_uid )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Display job status until it is completed.\n\nThe first job of a new deployment might take some time as a compute node must be started."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from time import sleep\n\nwhile job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n    sleep(5)\n    job_details=client.deployments.get_job_details(job_uid)\n\nprint( job_details['entity']['decision_optimization']['status']['state'])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='display'></a>\n### Extract and display solution\n\nDisplay the output solution.\n\nDisplay the KPI Total Calories value."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# Create a dataframe for the solution\nsolution = pd.DataFrame(job_details['entity']['decision_optimization']['output_data'][0]['values'], \n                        columns = job_details['entity']['decision_optimization']['output_data'][0]['fields'])\nsolution.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print( job_details['entity']['decision_optimization']['solve_state']['details']['KPI.Total Calories'] )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='problem'></a>\n###  Solve another problem using the same deployment\n\nCreate a new payload with modified input data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Change the input data\ndiet_nutrients.at[0,'qmin'] = 1500\ndiet_nutrients.at[0,'qmax'] = 2000\n\nsolve_payload = {\n    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n        {\n            \"id\":\"diet_food.csv\",\n            \"values\" : diet_food         \n        },\n        {\n            \"id\":\"diet_food_nutrients.csv\",\n             \"values\" : diet_food_nutrients            \n        },\n        {\n            \"id\":\"diet_nutrients.csv\",\n            \"values\" : diet_nutrients\n        }\n    ],\n    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n    {\n        \"id\":\".*\\.csv\"\n    }\n    ]\n}"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Create a new job."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "job_details = client.deployments.create_job(deployment_uid, solve_payload)\njob_uid = client.deployments.get_job_uid(job_details)\n\nprint( job_uid )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Display job status until it is completed."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n    sleep(5)\n    job_details=client.deployments.get_job_details(job_uid)\n\nprint( job_details['entity']['decision_optimization']['status']['state'])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Display the KPI Total Calories value for this modified data. "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print( job_details['entity']['decision_optimization']['solve_state']['details']['KPI.Total Calories'] )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(client.deployments.get_job_details(job_uid)['entity']['decision_optimization']['status'])"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Delete the deployment"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Use the following method to delete the deployment."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "client.deployments.delete(deployment_uid)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id='summary'></a>\n### Summary and next steps"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "You successfully completed this notebook! \n\nYou've learned how to:\n\n- work with the Watson Machine Learning client\n- prepare your model archive and upload your model on Watson Machine Learning\n- create a deployment\n- create and monitor a job with inline data for your deployed model\n- display the solution\n\nCheck out our online documentation at <a href=\"https://dataplatform.cloud.ibm.com/docs\" target=\"_blank\" rel=\"noopener noreferrer\">https://dataplatform.cloud.ibm.com/docs</a> for more samples, tutorials and documentation. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<hr>\nCopyright \u00a9 2019. This notebook and its source code are released under the terms of the MIT License."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}